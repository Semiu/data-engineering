{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47bec1e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d1753f",
   "metadata": {},
   "source": [
    "**A Glue Data Catalog** \n",
    "It represents many sources and destinations for data. They can represent Kafka, Kinesis, Redshift, S3, and many more. If we want to connect to another data source, we must add it to the catalog. This makes querying data much easier because just like catching a fish, we know where to look for the type of data we are looking for.\n",
    "\n",
    "**Glue Tables**\n",
    "A Glue Table is a definition of a specific group of fields that represents a logical entity. The Glue Catalog is made up of multiple table definitions. These tables are not physically stored in Glue. Glue tables are just a metadata catalog layer. They store a reference to the data we can query or store.\n",
    "\n",
    "There are multiple ways to create Glue Tables, and we will focus on three ways to define a Glue Table in a Glue Catalog:\n",
    "\n",
    "1. Use Glue Console to define each field\n",
    "2. Configure a Glue Job to generate a table definition automatically. \n",
    "3. Use SQL to define a table with DDL (Data Definition Language) or create statements.\n",
    "\n",
    "**Using the Glue Console to Define a Table**\n",
    "Imagine you have the Customer data we looked at earlier in an S3 bucket directory, and you want to know how many records have been placed in the Customer Landing Zone. You could create a Glue Table definition to query the data using SQL.\n",
    "\n",
    "Let's go over to the Glue Catalog in the Glue Console. Search for Glue Catalog in the AWS Console, and you will see the Glue Data Catalog. Click Data Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de720061",
   "metadata": {},
   "source": [
    "Then, \n",
    "* Click the Add database button\n",
    "* Enter the name of your database\n",
    "* Enter the name of the table you are defining, and the database it belongs in, and click next\n",
    "* Choose the data format, and click next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON data to guide the definition of the fields in the glue table\n",
    "{\n",
    "\"customerName\":\"Frank Doshi\",\n",
    "\"email\":\"Frank.Doshi@test.com\",\n",
    "\"phone\":\"8015551212\",\n",
    "\"birthDay\":\"1965-01-01\",\n",
    "\"serialNumber\":\"159a908a-371e-40c1-ba92-dcdea483a6a2\",\n",
    "\"registrationDate\":1655293787680,\n",
    "\"lastUpdateDate\":1655293787680,\n",
    "\"shareWithResearchAsOfDate\":1655293787680,\n",
    "\"shareWithPublicAsOfDate\":1655293787680\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d59d69",
   "metadata": {},
   "source": [
    "**AWS Athena - a Glue Catalog Query Tool**\n",
    "\n",
    "Now that you have defined a table using the glue catalog, you might want to query the table. \n",
    "\n",
    "Previously we had to use Spark SQL and relied on Spark schemas to query data. \n",
    "\n",
    "Using the Glue Data Catalog, we can query data using an AWS tool called Athena. The Athena tool is a serverless query service where you can write SQL to run ad-hoc queries on S3 buckets.\n",
    "\n",
    "Athena uses S3 to store query results. Set up the location Athena will use from now going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a409a",
   "metadata": {},
   "source": [
    "**Reverse Engineer a Table**\n",
    "\n",
    "Sometimes, it is helpful to pass on the schema definition in git, to other co-workers, for example. The easiest way to pass on a schema is through DDL (Data Definition Language) SQL statements. \n",
    "\n",
    "Now that you've generated a table in glue, you can reverse engineer it, or generate the SQL statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519c203",
   "metadata": {},
   "source": [
    "PII in the Landing Zone\n",
    "\n",
    "Ingesting Sensitive Data\n",
    "Before we can process sensitive accelerometer data, we need to bring it into the landing zone.\n",
    "\n",
    "Using the AWS Cloudshell or CLI, copy the accelerometer data into an S3 landing zone with the s3 cp command (where the blank is the S3 bucket you created earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws s3 cp ./project/starter/accelerometer/ s3://_______/accelerometer/landing/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb53f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws s3 ls s3://_______/accelerometer/landing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a9056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e0ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
