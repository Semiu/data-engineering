{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iCA-NLPTask-Solution2.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import the neccesary libraries \n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "_Mys4Pb9iDVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the CSV data file - mounted on my Google Drive\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/Task_data (1) (3).csv\""
      ],
      "metadata": {
        "id": "DBczriJziDSX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert the CSV file to a dataframe. It takes the path to the data file as parameter and returns a dataframe of the data\n",
        "\n",
        "def csv_to_df(path):\n",
        "  datadf = pd.read_csv(path, low_memory=False)\n",
        "  return datadf"
      ],
      "metadata": {
        "id": "w2LqPzkRiDPm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function takes a text description as a parameter and returns three lists which categorise the content of the text description into device\n",
        "# patient, and any other one\n",
        "\n",
        "def extract_keyword_corpus(text_desr):\n",
        "\n",
        "  device_problem = []\n",
        "  patient_problem = []\n",
        "  other_problem = []\n",
        "  \n",
        "  global final_device_problem_keyphrases, final_patient_problem_keyphrases, final_other_problem_keyphrases\n",
        "  \n",
        "  text_list = text_desr.split('.')\n",
        "  \n",
        "  for text in text_list:\n",
        "    if bool(re.search(\"device\", text, re.IGNORECASE)):\n",
        "      device_problem.append(text)\n",
        "    \n",
        "    elif bool(re.search(\"patient\", text, re.IGNORECASE)):\n",
        "      patient_problem.append(text)\n",
        "      \n",
        "    else:\n",
        "      other_problem.append(text)\n",
        "  \n",
        "  if len(device_problem) > 0:\n",
        "    device_problem_keyphrases = [d_problem.split('device')[1] for d_problem in device_problem]\n",
        "    device_problem_keyphrases = [device_problem_keyphrases.split(',') for device_problem_keyphrases in device_problem_keyphrases]\n",
        "    final_device_problem_keyphrases = [item.lstrip() for sublist in device_problem_keyphrases for item in sublist]\n",
        "  \n",
        "  elif len(device_problem) == 0:\n",
        "    final_device_problem_keyphrases = device_problem\n",
        "  \n",
        "  if len(patient_problem) > 0:\n",
        "    patient_problem_keyphrases = [p_problem.split('patient')[1] for p_problem in patient_problem]\n",
        "    patient_problem_keyphrases = [patient_problem_keyphrases.split(',') for patient_problem_keyphrases in patient_problem_keyphrases]\n",
        "    final_patient_problem_keyphrases = [item.lstrip() for sublist in patient_problem_keyphrases for item in sublist]\n",
        "  \n",
        "  elif len(patient_problem) == 0:\n",
        "    final_patient_problem_keyphrases = patient_problem\n",
        "  \n",
        "  if len(other_problem) > 0:\n",
        "    other_problem_keyphrases = [o_problem.split(',') for o_problem in other_problem]\n",
        "    final_other_problem_keyphrases = [item.lstrip() for sublist in other_problem_keyphrases for item in sublist]\n",
        "  \n",
        "  elif len(other_problem) == 0:\n",
        "    final_other_problem_keyphrases = other_problem\n",
        "  \n",
        "  return final_device_problem_keyphrases,  final_patient_problem_keyphrases, final_other_problem_keyphrases"
      ],
      "metadata": {
        "id": "S4fhs_oXihFF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_desr = '(b)(4). this reported event and subsequent repairs were investigated through the service repair process. failure data and parts-used information were reviewed for the sap and track wise files and found relevant to the service repair. a review of the device service history record was performed from the date of manufacture to the date corresponding to this service notification number. the database showed no quality notifications were opened for the device. a review of the device history record in sap for sn (b)(4) was performed from the date of the manufacture to date of the release of product, which confirmed that this device was not involved in a production failure, and product was returned for servicing which correlates to the customer reported issue. a trackwise complaint history review was completed, and it was confirmed that there were additional complaints received with similar sn (b)(4) for the same or related failure mode. the customer stated that there was no patient involvement.'"
      ],
      "metadata": {
        "id": "yf3IGnzbX_sV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize WordNetLemmatizer for the NLP processing\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "0eWczx8FTsto"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create stop words from fundamental English stop words\n",
        "# The stopwords.txt file is a collection of English words that should be eliminated because they do not add any important meaning\n",
        "\n",
        "stopwords = set(w.rstrip() for w in open('/content/drive/MyDrive/stopwords.txt'))\n",
        "\n",
        "# Adding more stopwords specific to this problem - as seen in the raw data\n",
        "# This would be iterately expanded to optimize the performance of the tokenizer\n",
        "\n",
        "stopwords = stopwords.union({'wa','reported'})"
      ],
      "metadata": {
        "id": "IxlpQGbLRy60"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Text pre-processing function\n",
        "# This function tokenizes each sentence in the problem list provided, and returns a new list of tokens and any numeric value found \n",
        "\n",
        "def my_tokenizer(sentence):\n",
        "  \n",
        "  eliminate_words = [',',\"'\",'.','(',')','{','}',':','e.g',';', '@', '{}', '()'] # This can also be increased to \n",
        "  sentence = sentence.lower() # downcase\n",
        "  tokens = nltk.tokenize.word_tokenize(sentence) # split string into words (tokens)\n",
        "  tokens = [t for t in tokens if len(t) > 2 or len(t)==1]   # remove short words, they're probably not useful\n",
        "  tokens = [t for t in tokens if t not in eliminate_words] # Remove those weird characters in the eliminate_words list\n",
        "  tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
        "  tokens = [t for t in tokens if t not in stopwords] # remove stopwords\n",
        "  digits = [t for t in tokens if any(c.isdigit() for c in t)] # get the digits seperately (probably these are the scores)\n",
        "  \n",
        "  return \" \".join(tokens), digits"
      ],
      "metadata": {
        "id": "-Iay3gb4ReS0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function takes the text description as a parameter, passes it to the extract_keyword_corpus function.\n",
        "# The returned values from the extract_keyword_corpus function are further processed to get a dictionary data structure for the required features\n",
        "# This function returns a dictionary where the key-values are the six columns to be populated in the dataframe\n",
        "\n",
        "def extract_keywords_dict(text_desr):\n",
        "  \n",
        "  keyword_corpus = extract_keyword_corpus(text_desr) #The extract_keyword_corpus function is called here\n",
        "\n",
        "  keyword_corpus_device = keyword_corpus[0]\n",
        "  keyword_corpus_patient = keyword_corpus[1]\n",
        "  keyword_corpus_other = keyword_corpus[2]\n",
        "\n",
        "  keywords_dict = {}\n",
        "  \n",
        "  device_keywords = []\n",
        "  device_score = []\n",
        "  patient_keywords = []\n",
        "  patient_score = []\n",
        "  other_keywords = []\n",
        "  other_score = []\n",
        "  \n",
        "  if len(keyword_corpus_device) > 0:\n",
        "    for sent_d in keyword_corpus_device:\n",
        "      sentence_tokens = my_tokenizer(sent_d) # The tokenizer function is called here\n",
        "      device_keywords.append(sentence_tokens[0])\n",
        "      if len(sentence_tokens[1]) > 1:\n",
        "        joined_digits = \" \".join(sentence_tokens[1])\n",
        "        device_score.append(joined_digits)\n",
        "      elif len(sentence_tokens[1]) == 1:\n",
        "        digits = sentence_tokens[1][0]\n",
        "        device_score.append(digits)\n",
        "  \n",
        "  elif len(keyword_corpus_patient) > 0:\n",
        "    for sent_p in keyword_corpus_patient:\n",
        "      sentence_tokens = my_tokenizer(sent_p) # The tokenizer function is called here\n",
        "      patient_keywords.append(sentence_tokens[0])\n",
        "      if len(sentence_tokens[1]) > 1:\n",
        "        joined_digits = \" \".join(sentence_tokens[1])\n",
        "        patient_score.append(joined_digits)\n",
        "      elif len(sentence_tokens[1]) == 1:\n",
        "        digits = sentence_tokens[1][0]\n",
        "        patient_score.append(digits)\n",
        "  \n",
        "  elif len(keyword_corpus_other) > 0:\n",
        "    for sent_o in keyword_corpus_other:\n",
        "      sentence_tokens = my_tokenizer(sent_o) # The tokenizer function is called here\n",
        "      other_keywords.append(sentence_tokens[0])\n",
        "      if len(sentence_tokens[1]) > 1:\n",
        "        joined_digits = \" \".join(sentence_tokens[1])\n",
        "        other_score.append(joined_digits)\n",
        "      elif len(sentence_tokens[1]) == 1:\n",
        "        digits = sentence_tokens[1][0]\n",
        "        other_score.append(digits)\n",
        "  \n",
        "  keywords_dict[\"keywords (Device Problems)\"] = device_keywords\n",
        "  keywords_dict[\"keywords (Device Problems)_score\"] = device_score\n",
        "  keywords_dict[\"keywords (Patient Problems)\"] = patient_keywords\n",
        "  keywords_dict[\"keywords (Patient Problems)_score\"] = patient_score\n",
        "  keywords_dict[\"keywords others (interesting ones)\"] = other_keywords\n",
        "  keywords_dict[\"keywords others (interesting ones)_score\"] = other_score\n",
        "\n",
        "  return keywords_dict"
      ],
      "metadata": {
        "id": "Ljt7TjqLReP3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for process the data frame as required\n",
        "\n",
        "def process_df(datadf):\n",
        "\n",
        "  # row index starts from zero\n",
        "  idx = 0\n",
        "\n",
        "  while idx <= len(datadf)-1:\n",
        "\n",
        "    for text in datadf[\"TEXT DESCRIPTION\"]:\n",
        "\n",
        "\n",
        "      keywords_to_use = extract_keywords_dict(text) # The extract_keywords_dict function is called here\n",
        "      \n",
        "      try:\n",
        "        datadf.iloc[[idx],[3]] = keywords_to_use.get(\"keywords (Device Problems)\", \"Not available\")\n",
        "        datadf.iloc[[idx], [4]] = keywords_to_use.get(\"keywords (Device Problems)_score\", \"Not available\")\n",
        "        datadf.iloc[[idx], [5]] = keywords_to_use.get(\"keywords (Patient Problems)\", \"Not available\")\n",
        "        datadf.iloc[[idx], [6]] = keywords_to_use.get(\"keywords (Patient Problems)_score\", \"Not available\")\n",
        "        datadf.iloc[[idx], [7]] = keywords_to_use.get(\"keywords others (interesting ones)\", \"Not available\")\n",
        "        datadf.iloc[[idx], [8]] = keywords_to_use.get(\"keywords others (interesting ones)_score\", \"Not available\")\n",
        "\n",
        "      except ValueError: # This ValueError is exempted because we are passing lists of different lengths, and they contain different num of items to update the dataframe\n",
        "        continue\n",
        "\n",
        "      idx += 1\n",
        "\n",
        "  return datadf"
      ],
      "metadata": {
        "id": "FsX2rZXhReKQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the csv_to_df function that opens the CSV file into a dataframe\n",
        "\n",
        "data_df = csv_to_df(data_path)\n",
        "\n",
        "copy_data_df = data_df.copy(deep = True)"
      ],
      "metadata": {
        "id": "ejCZHrHPIYD0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "part_copy_data_df = copy_data_df[:20]"
      ],
      "metadata": {
        "id": "Gx7w9hdlWjAJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "part_copy_data_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "uRhv5CfiW20q",
        "outputId": "1f38eccb-22bc-434c-cfb7-fcff76404f36"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   RN        RK  \\\n",
              "0  2016493-2021-17616  11224049   \n",
              "1  2016493-2020-85916  11101248   \n",
              "2  2031642-2020-00098   9565035   \n",
              "3  2016493-2020-39626  10835372   \n",
              "4  2016493-2020-42584  10858883   \n",
              "\n",
              "                                    TEXT DESCRIPTION  \\\n",
              "0  it was reported that the device failed prevent...   \n",
              "1  fails calibration. replaced linear sensor, fro...   \n",
              "2  the customer reported a noise was heard at the...   \n",
              "3  (b)(4). this reported event and subsequent rep...   \n",
              "4  (b)(4). this reported event and subsequent rep...   \n",
              "\n",
              "   keywords (Device Problems)  keywords (Device Problems)_score  \\\n",
              "0                         NaN                               NaN   \n",
              "1                         NaN                               NaN   \n",
              "2                         NaN                               NaN   \n",
              "3                         NaN                               NaN   \n",
              "4                         NaN                               NaN   \n",
              "\n",
              "   keywords (Patient Problems)  keywords (Patient Problems)_score  \\\n",
              "0                          NaN                                NaN   \n",
              "1                          NaN                                NaN   \n",
              "2                          NaN                                NaN   \n",
              "3                          NaN                                NaN   \n",
              "4                          NaN                                NaN   \n",
              "\n",
              "   keywords others (interesting ones)  \\\n",
              "0                                 NaN   \n",
              "1                                 NaN   \n",
              "2                                 NaN   \n",
              "3                                 NaN   \n",
              "4                                 NaN   \n",
              "\n",
              "   keywords others (interesting ones)_score  \\\n",
              "0                                       NaN   \n",
              "1                                       NaN   \n",
              "2                                       NaN   \n",
              "3                                       NaN   \n",
              "4                                       NaN   \n",
              "\n",
              "                                              MDR PP  \\\n",
              "0                            ['F27' 'E2403' 'A0509']   \n",
              "1  ['F27' 'A0401' 'A0404' 'A040502' 'A25' 'A0509'...   \n",
              "2                                          ['A0508']   \n",
              "3  ['F27' 'A0401' 'A0404' 'F24' 'E2401' 'A26' 'A0...   \n",
              "4                    ['F27' 'A0404' 'A2305' 'A0509']   \n",
              "\n",
              "                          NLP PP  \n",
              "0      ['A1301', 'F27', 'E2403']  \n",
              "1    ['F27', 'A0404', 'A070903']  \n",
              "2  ['A0508', 'E2330', 'A090201']  \n",
              "3      ['F27', 'A0404', 'A0401']  \n",
              "4      ['F27', 'A0404', 'A0401']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bde05a93-5ba9-4aba-b81d-0cfe307d768f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RN</th>\n",
              "      <th>RK</th>\n",
              "      <th>TEXT DESCRIPTION</th>\n",
              "      <th>keywords (Device Problems)</th>\n",
              "      <th>keywords (Device Problems)_score</th>\n",
              "      <th>keywords (Patient Problems)</th>\n",
              "      <th>keywords (Patient Problems)_score</th>\n",
              "      <th>keywords others (interesting ones)</th>\n",
              "      <th>keywords others (interesting ones)_score</th>\n",
              "      <th>MDR PP</th>\n",
              "      <th>NLP PP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016493-2021-17616</td>\n",
              "      <td>11224049</td>\n",
              "      <td>it was reported that the device failed prevent...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['F27' 'E2403' 'A0509']</td>\n",
              "      <td>['A1301', 'F27', 'E2403']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016493-2020-85916</td>\n",
              "      <td>11101248</td>\n",
              "      <td>fails calibration. replaced linear sensor, fro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['F27' 'A0401' 'A0404' 'A040502' 'A25' 'A0509'...</td>\n",
              "      <td>['F27', 'A0404', 'A070903']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2031642-2020-00098</td>\n",
              "      <td>9565035</td>\n",
              "      <td>the customer reported a noise was heard at the...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['A0508']</td>\n",
              "      <td>['A0508', 'E2330', 'A090201']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016493-2020-39626</td>\n",
              "      <td>10835372</td>\n",
              "      <td>(b)(4). this reported event and subsequent rep...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['F27' 'A0401' 'A0404' 'F24' 'E2401' 'A26' 'A0...</td>\n",
              "      <td>['F27', 'A0404', 'A0401']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016493-2020-42584</td>\n",
              "      <td>10858883</td>\n",
              "      <td>(b)(4). this reported event and subsequent rep...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['F27' 'A0404' 'A2305' 'A0509']</td>\n",
              "      <td>['F27', 'A0404', 'A0401']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bde05a93-5ba9-4aba-b81d-0cfe307d768f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bde05a93-5ba9-4aba-b81d-0cfe307d768f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bde05a93-5ba9-4aba-b81d-0cfe307d768f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data_df = process_df(part_copy_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_duwBfyW2xU",
        "outputId": "5de716db-6dba-48ea-ad9f-c24a3cea2665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(ilocs[0], value, pi)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the process_df function\n",
        "\n",
        "processed_data_df = process_df(data_df)"
      ],
      "metadata": {
        "id": "8THcs-5dXgC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first 20 rows of the processed data frame\n",
        "\n",
        "processed_data_df.head(20)"
      ],
      "metadata": {
        "id": "RL3ItHZTIYAN"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the processed data frame in CSV format - change the file name not to override the unprocessed data\n",
        "\n",
        "def save_processeddf(processed_datadf):\n",
        "  processed_datadf.to_csv(\"/content/drive/MyDrive/processed_Task_data (1) (3).csv\", encoding='utf-8', index=None)"
      ],
      "metadata": {
        "id": "AfaLWDEJ-IaJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the save_processeddf function\n",
        "\n",
        "save_processeddf(processed_data_df)"
      ],
      "metadata": {
        "id": "_Dsz0f4rDlGi"
      },
      "execution_count": 73,
      "outputs": []
    }
  ]
}